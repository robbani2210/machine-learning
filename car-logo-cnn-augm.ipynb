{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T02:29:02.904013Z","iopub.execute_input":"2022-06-07T02:29:02.904386Z","iopub.status.idle":"2022-06-07T02:29:02.919914Z","shell.execute_reply.started":"2022-06-07T02:29:02.904322Z","shell.execute_reply":"2022-06-07T02:29:02.918899Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\n\n# Importing scikit-learn tools\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# Importing standard ML set - numpy, pandas, matplotlib\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\n# Importing keras and its deep learning tools - neural network model, layers, contraints, optimizers, callbacks and utilities\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.utils import np_utils\nfrom keras.regularizers import l2\nfrom keras.initializers import RandomNormal, VarianceScaling\n\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-06-07T02:29:02.920842Z","iopub.execute_input":"2022-06-07T02:29:02.921039Z","iopub.status.idle":"2022-06-07T02:29:04.953451Z","shell.execute_reply.started":"2022-06-07T02:29:02.921008Z","shell.execute_reply":"2022-06-07T02:29:04.952461Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/images/images/'\nimgs = os.listdir(image_path)\nimg_x = img_y = 50 # image size is constant\nn_samples = np.size(imgs)\nn_samples # 20778 originally\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:29:04.956026Z","iopub.execute_input":"2022-06-07T02:29:04.956680Z","iopub.status.idle":"2022-06-07T02:29:05.343258Z","shell.execute_reply.started":"2022-06-07T02:29:04.956621Z","shell.execute_reply":"2022-06-07T02:29:05.342242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n# loading all images\nimages = np.array([ np.array( Image.open(image_path+img).convert(\"RGB\") ).flatten() for img in imgs], order='F', dtype='uint8')\n# Mỗi ảnh có kích thước 50x50 = 2500 pixel và 3 kênh màu = 7500 pixel\nprint('total images: ', np.shape(images) )\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:29:05.344410Z","iopub.execute_input":"2022-06-07T02:29:05.344618Z","iopub.status.idle":"2022-06-07T02:30:11.457782Z","shell.execute_reply.started":"2022-06-07T02:29:05.344585Z","shell.execute_reply":"2022-06-07T02:30:11.456890Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Producing label and assigning them accordingly\nimport re\ncars = ['Alfa Romeo', 'Audi', 'BMW', 'Chevrolet', 'Citroen', 'Dacia', 'Daewoo', 'Dodge',\n        'Ferrari', 'Fiat', 'Ford', 'Honda', 'Hyundai', 'Jaguar', 'Jeep', 'Kia', 'Lada',\n        'Lancia', 'Land Rover', 'Lexus', 'Maserati', 'Mazda', 'Mercedes', 'Mitsubishi',\n        'Nissan', 'Opel', 'Peugeot', 'Porsche', 'Renault', 'Rover', 'Saab', 'Seat',\n        'Skoda', 'Subaru', 'Suzuki', 'Tata', 'Tesla', 'Toyota', 'Volkswagen', 'Volvo']\n# re.match()[0] lấy về tên car , car.index trả về index ứng với tên car vd: Daewoo index là 6 (cars[6] = 'Daewoo')\nlabels = np.array([ cars.index(re.match(r\"(^\\D+)\", imgs[i])[0]) for i in range(n_samples)])\nprint('total label images: ', labels.shape )\nlabels_pd = pd.DataFrame(labels)\nlabels_pd[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:11.459151Z","iopub.execute_input":"2022-06-07T02:30:11.459678Z","iopub.status.idle":"2022-06-07T02:30:11.535996Z","shell.execute_reply.started":"2022-06-07T02:30:11.459621Z","shell.execute_reply":"2022-06-07T02:30:11.535027Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# preparation data\ndataset, labelset = shuffle(images, labels, random_state=42)\ntrain_data = [dataset, labelset]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:11.537419Z","iopub.execute_input":"2022-06-07T02:30:11.537768Z","iopub.status.idle":"2022-06-07T02:30:13.497039Z","shell.execute_reply.started":"2022-06-07T02:30:11.537702Z","shell.execute_reply":"2022-06-07T02:30:13.496284Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# an example image\nr=1260\nplt.imshow(images[r].reshape(img_x, img_y, 3))\nplt.title(cars[labels[r]])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:13.497984Z","iopub.execute_input":"2022-06-07T02:30:13.498341Z","iopub.status.idle":"2022-06-07T02:30:13.734488Z","shell.execute_reply.started":"2022-06-07T02:30:13.498302Z","shell.execute_reply":"2022-06-07T02:30:13.733562Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Training and preparing dataset\nX_train, X_test, y_train, y_test = train_test_split( train_data[0], train_data[1], test_size=0.2)\n# Maintain a copy of testset\nX_test_img = X_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:13.735940Z","iopub.execute_input":"2022-06-07T02:30:13.736509Z","iopub.status.idle":"2022-06-07T02:30:13.830173Z","shell.execute_reply.started":"2022-06-07T02:30:13.736439Z","shell.execute_reply":"2022-06-07T02:30:13.829150Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# bring images back size (20778, 50, 50,3)\ndef ImageConvert(n, i):\n    im_ex = i.reshape(n, img_x, img_y, 3)\n    im_ex = im_ex.astype('float32') / 255\n    # zero center data\n    im_ex = np.subtract(im_ex, 0.5)\n    # ...and to scale it to (-1, 1)\n    im_ex = np.multiply(im_ex, 2.0)\n    return im_ex\nX_train = ImageConvert(X_train.shape[0], X_train)\nX_test = ImageConvert(X_test.shape[0], X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:13.831369Z","iopub.execute_input":"2022-06-07T02:30:13.831636Z","iopub.status.idle":"2022-06-07T02:30:15.110214Z","shell.execute_reply.started":"2022-06-07T02:30:13.831585Z","shell.execute_reply":"2022-06-07T02:30:15.109419Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Labels have to be transformed to categorical\nY_train = np_utils.to_categorical(y_train, num_classes=len(cars))\nY_test = np_utils.to_categorical(y_test, num_classes=len(cars))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:15.111939Z","iopub.execute_input":"2022-06-07T02:30:15.112469Z","iopub.status.idle":"2022-06-07T02:30:15.119223Z","shell.execute_reply.started":"2022-06-07T02:30:15.112410Z","shell.execute_reply":"2022-06-07T02:30:15.118334Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Four Conv/MaxPool blocks, a flattening layer and two dense layers at the end\ndef contruction(n_channels):\n    model = Sequential()\n    model.add(Conv2D(32, (3,3),\n                     input_shape=(img_x,img_y,n_channels),\n                     padding='valid',\n                     bias_initializer='glorot_uniform',\n                     kernel_regularizer=l2(0.00004),\n                     kernel_initializer=VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None),\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    \n    model.add(Conv2D(64, (3,3),\n                     padding='valid',\n                     bias_initializer='glorot_uniform',\n                     kernel_regularizer=l2(0.00004),\n                     kernel_initializer=VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None),\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    \n    model.add(Conv2D(128, (3,3),\n                     padding='valid',\n                     bias_initializer='glorot_uniform',\n                     kernel_regularizer=l2(0.00004),\n                     kernel_initializer=VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None),\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    \n    model.add(Conv2D(256, (3,3),\n                     padding='valid',\n                     bias_initializer='glorot_uniform',\n                     kernel_regularizer=l2(0.00004),\n                     kernel_initializer=VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None),\n                     activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(4096, activation='relu', bias_initializer='glorot_uniform'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(4096, activation='relu', bias_initializer='glorot_uniform'))\n    model.add(Dropout(0.5))\n    \n    # final activation is softmax, tuned to the number of classes/labels possible\n    model.add(Dense(len(cars), activation='softmax'))\n    \n    # optimizer will be a stochastic gradient descent, learning rate set at 0.005\n    sgd = SGD(lr=0.005, decay=1e-6, momentum=0.95, nesterov=True)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['categorical_accuracy'])\n    return model\nmodel = contruction(3)\n# Let's look at the summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:15.120707Z","iopub.execute_input":"2022-06-07T02:30:15.120980Z","iopub.status.idle":"2022-06-07T02:30:15.487837Z","shell.execute_reply.started":"2022-06-07T02:30:15.120921Z","shell.execute_reply":"2022-06-07T02:30:15.487052Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Some callbacks have to be provided to choose the best trained model\n# patience set at 4 as 3 was too greedy - I observed better results after the third-worse epoch\nearly_stopping = EarlyStopping(patience=6, monitor='val_loss')\nCNN_file = 'car_CNN_9AUGM_CMCMCMCMF.h5py' # the 13th try, with augmented data\ntake_best_model = ModelCheckpoint(CNN_file, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:15.489163Z","iopub.execute_input":"2022-06-07T02:30:15.489421Z","iopub.status.idle":"2022-06-07T02:30:15.494363Z","shell.execute_reply.started":"2022-06-07T02:30:15.489372Z","shell.execute_reply":"2022-06-07T02:30:15.493553Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Data augumentation**","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nimage_gen = ImageDataGenerator(\n    #featurewise_center=True,\n    #featurewise_std_normalization=True,\n    rotation_range=45,\n    width_shift_range=.15,\n    height_shift_range=.15,\n    horizontal_flip=True,\n    vertical_flip=True)\n\n#training the image preprocessing\nimage_gen.fit(X_train, augment=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:15.495543Z","iopub.execute_input":"2022-06-07T02:30:15.495789Z","iopub.status.idle":"2022-06-07T02:30:28.086831Z","shell.execute_reply.started":"2022-06-07T02:30:15.495739Z","shell.execute_reply":"2022-06-07T02:30:28.085611Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Train after augumentation **","metadata":{}},{"cell_type":"code","source":"NUM_EPOCHS = 100\nBATCH_SIZE = 128\n\n\n# monitor the validation accuracy, reduce the learning rate by factor when there is no improvement after the number of patience \nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', \n                              factor=0.3, \n                              patience=3, \n                              min_lr=0.0001)\n\ncallbacks_list = [reduce_lr, early_stopping, take_best_model]\n\nhistory = model.fit_generator(image_gen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n                              steps_per_epoch=X_train.shape[0]//BATCH_SIZE,\n                              epochs=NUM_EPOCHS,\n                              verbose=1,\n                              validation_data=(X_test, Y_test),\n                              callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T02:30:28.088495Z","iopub.execute_input":"2022-06-07T02:30:28.088843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save_weights(\"car_CNN_AUGM_CMCMCMCMF.h5\")\n# Plot the training and validation loss + accuracy\ndef plot_training(history):\n    acc = history.history['categorical_accuracy']\n    val_acc = history.history['val_categorical_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'r.')\n    plt.plot(epochs, val_acc, 'r')\n    plt.title('Training and validation accuracy')\n\n    # plt.figure()\n    # plt.plot(epochs, loss, 'r.')\n    # plt.plot(epochs, val_loss, 'r-')\n    # plt.title('Training and validation loss')\n    plt.show()\n    \nplot_training(history)\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n\n#print(\"Saved model to disk\")\nscores = model.evaluate(X_test, Y_test) # let's look at the accuracy on the test set\nprint(\"Accuracy test: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Metrics of success**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as prfs\n\n# Preparing for metrics check-up on the test set, may take a while...\nY_pred = model.predict_classes(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision, recall, f1, support = prfs(y_test, Y_pred, average='weighted')\nprint(\"Precision: {:.2%}\\nRecall: {:.2%}\\nF1 score: {:.2%}\\nAccuracy: {:.2%}\".format(precision, recall, f1, scores[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport seaborn as sns #for better and easier plots\n\ndef report_and_confusion_matrix(label, prediction):\n    print(\"Model Report\")\n    print(classification_report(label, prediction))\n    score = accuracy_score(label, prediction)\n    print(\"Accuracy : \"+ str(score))\n    \n    ####################\n    fig, ax = plt.subplots(figsize=(8,8)) #setting the figure size and ax\n    mtx = confusion_matrix(label, prediction)\n    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.5,  cbar=True, ax=ax) #create a heatmap with the values of our confusion matrix\n    plt.ylabel('true label')\n    plt.xlabel('predicted label')\n\nreport_and_confusion_matrix(y_test, Y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# But let's check per class, too - assuming that larger datasets will be having higher metrics\nprecision_, recall_, f1_, support_ = prfs(y_test, Y_pred, average=None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We see that smaller sets (Lexus, Jaguar, Hyundai) have generally worse precision and recall\nplt.subplots(figsize=(18,30))\nx = range(len(cars))\nplt.subplot(311)\nplt.title('Precision per class')\nplt.ylim(0.5, 1.00)\nplt.bar(x, precision_, color='Red')\nplt.xticks(x, cars, rotation = 90)\nplt.subplot(312)\nplt.title('Recall per class')\nplt.ylim(0.5, 1.00)\nplt.bar(x, recall_, color='Green')\nplt.xticks(x, cars, rotation = 90)\nplt.subplot(313)\nplt.title('F1 score per class')\nplt.ylim(0.5, 1.00)\nplt.bar(x, f1_, color='Blue')\nplt.xticks(x, cars, rotation = 90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OK, let's try the CNN in action - first defining the ShowCase() method to show everything nicely\n\ndef ShowCase(cols, rows):\n    fdict = {'fontsize': 24,\n            'fontweight' : 'normal',\n            'verticalalignment': 'baseline'}\n    plt.figure(figsize=(cols * 5, rows * 4))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    c = 0\n    for i in range(rows * cols):\n        plt.subplot(rows, cols, i + 1)\n        \n        # r - randomly picked from the whole dataset\n        r = np.random.randint(np.shape(images)[0])\n        \n        # j - predicted class for the image of index r (weird syntax, but works :)\n        j = int(model.predict_classes(ImageConvert(1, images[r:r+1]), verbose=0))\n        \n        # increase success if predicted well\n        if labels[r] == j:\n            c += 1\n        \n        # image needs reshaping back to a 50px*50px*RGB\n        plt.imshow(images[r].reshape(img_x, img_y, 3))\n        \n        # plt.title will show the true brand and the predicted brand\n        plt.title('True brand: '+cars[labels[r]]+'\\nPredicted: '+cars[j],\n                  color= 'Green' if cars[labels[r]] == cars[j] else 'Red', fontdict=fdict) # Green for right, Red for wrong\n        \n        # no ticks\n        plt.xticks(())\n        plt.yticks(())\n        \n    # print out the success rate\n    print('Success rate: {}/{} ({:.2%})'.format(c, rows*cols, c/(rows*cols)))\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# That is strictly for the showcasing, how the CNN works - ain't that bad, after all :)\nShowCase(10, 5)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predict new images **","metadata":{}},{"cell_type":"code","source":"new_image_path = '../input/images/new_images/'\nnew_imgs = os.listdir(new_image_path)\nnew_n_samples = np.size(new_imgs)\nnew_n_samples # 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = 8\nrows = 1\nplt.figure(figsize=(cols * 5, rows * 4))\nplt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\nfor i in range(new_n_samples):\n    plt.subplot(rows, cols, i + 1)\n    im = Image.open(new_image_path+new_imgs[i]).convert(\"RGB\")\n    new_im = np.array(im.resize((50,50))).flatten()\n    m = int(model.predict_classes(ImageConvert(1, new_im), verbose=0))\n    plt.imshow(new_im.reshape(img_x, img_y, 3))\n    plt.title('Predicted brand: '+cars[m], size=24)\n    plt.xticks(())\n    plt.yticks(())\nplt.show() # 5/8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Deeplearning ResNet50**","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\n\nHEIGHT = 50\nWIDTH = 50\nbase_model = ResNet50(weights='imagenet', \n                      include_top=False, \n                    input_shape=(HEIGHT, WIDTH, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data generator **","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nimage_gen = ImageDataGenerator(\n    #featurewise_center=True,\n    #preprocessing_function=preprocess_input,\n    rotation_range=45,\n    width_shift_range=.15,\n    height_shift_range=.15,\n    horizontal_flip=True,\n    vertical_flip=True)\n\n#training the image preprocessing\nimage_gen.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n#     for layer in base_model.layers[:13]:\n#         layer.trainable = False\n        \n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        # New FC layer, random init\n        x = Dense(fc, activation='relu')(x) \n        x = Dropout(dropout)(x)\n\n    # New softmax layer\n    predictions = Dense(num_classes, activation='softmax')(x) \n    \n    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n\n    return finetune_model\n\n\nFC_LAYERS = [1024, 1024]\ndropout = 0.5\n\nfinetune_model = build_finetune_model(base_model, \n                                      dropout=dropout, \n                                      fc_layers=FC_LAYERS, \n                                        num_classes=len(cars))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 10\nBATCH_SIZE = 128\n\n\nadam = Adam(lr=0.00001)\nsgd = SGD(lr=0.0005, decay=1e-6, momentum=0.95, nesterov=True)\nfinetune_model.compile(adam, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n\n# Some callbacks have to be provided to choose the best trained model\n# patience set at 4 as 3 was too greedy - I observed better results after the third-worse epoch\nearly_stopping = EarlyStopping(patience=8, monitor='val_loss')\nResNet_file = 'car_ResNet_AUGM.h5py' # the 13th try, with augmented data\ntake_best_model = ModelCheckpoint(ResNet_file, save_best_only=True)\n\n\nfilepath=\"ResNet50\" + \"_model_weights.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor=[\"categorical_accuracy\"], verbose=1, mode='max')\n\ncallbacks_list = [take_best_model,early_stopping]\n\n\ncallbacks_list = [early_stopping, take_best_model]\n\nfitted_model = finetune_model.fit_generator(image_gen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n                                          steps_per_epoch=X_train.shape[0]//BATCH_SIZE,\n                                          epochs=NUM_EPOCHS,\n                                          shuffle=True,\n                                          verbose=1,\n                                          validation_data=(X_test, Y_test),\n                                          callbacks=callbacks_list)\n\npd.DataFrame(fitted_model.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ResNet50 with finetune**","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\n\n# create the base pre-trained model\nbase_model = ResNet50(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(len(cars), activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional ResNet layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nNUM_EPOCHS = 5\nBATCH_SIZE = 128\n# train the model on the new data for a few epochs\nmodel.fit_generator(image_gen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n                                  steps_per_epoch=len(X_train)//BATCH_SIZE,\n                                  epochs=NUM_EPOCHS)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from ResNet. We will freeze the bottom N layers\n# and train the remaining top layers.\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\n# for layer in model.layers[:249]:\n#    layer.trainable = False\n# for layer in model.layers[249:]:\n#    layer.trainable = True\nfor layer in model.layers:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\n# we use SGD with a low learning rate\nfrom keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\n# Some callbacks have to be provided to choose the best trained model\n# patience set at 4 as 3 was too greedy - I observed better results after the third-worse epoch\nearly_stopping = EarlyStopping(patience=8, monitor='val_loss')\nInceptionV3_file = 'car_ResNet_AUGM.h5py' # the 13th try, with augmented data\ntake_best_model = ModelCheckpoint(InceptionV3_file, save_best_only=True)\ncallbacks_list = [take_best_model,early_stopping]\n\n# we train our model again (this time fine-tuning the top 2 inception blocks\n# alongside the top Dense layers\nNUM_EPOCHS = 100\nfitted_model2 = model.fit_generator(image_gen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n                                      steps_per_epoch=len(X_train)//BATCH_SIZE,\n                                      epochs=NUM_EPOCHS,\n                                      verbose=1,\n                                      validation_data=(X_test, Y_test),\n                                      callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the weights\nmodel.save_weights('car_ResNet_AUGM_weights.h5')\n\n# Save the model architecture\nwith open('model_car_ResNet_AUGM.json', 'w') as f:\n    f.write(model.to_json())\n\n#print(\"Saved model to disk\")\nscores = model.evaluate(X_test, Y_test) # let's look at the accuracy on the test set\nprint(\"Accuracy test: %.2f%%\" % (scores[1]*100))\n\npd.DataFrame(fitted_model2.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as prfs\nY_pred = model.predict(X_test)\nY_pred = np.argmax(Y_pred,axis=1)\n\nprecision, recall, f1, support = prfs(y_test, Y_pred, average='weighted')\nprint(\"Precision: {:.2%}\\nRecall: {:.2%}\\nF1 score: {:.2%}\\nAccuracy: {:.2%}\".format(precision, recall, f1, scores[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some new image","metadata":{}},{"cell_type":"code","source":"new_image_path = '../input/images/new_images/'\nnew_imgs = os.listdir(new_image_path)\nnew_n_samples = np.size(new_imgs)\nnew_n_samples # 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = 8\nrows = 1\nplt.figure(figsize=(cols * 5, rows * 4))\nplt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\nfor i in range(new_n_samples):\n    plt.subplot(rows, cols, i + 1)\n    im = Image.open(new_image_path+new_imgs[i]).convert(\"RGB\")\n    new_im = np.array(im.resize((50,50))).flatten()\n    m = int(np.argmax(model.predict(ImageConvert(1, new_im), verbose=0),axis=1))\n    plt.imshow(new_im.reshape(img_x, img_y, 3))\n    plt.title('Predicted brand: '+cars[m], size=24)\n    plt.xticks(())\n    plt.yticks(())\nplt.show() ","metadata":{},"execution_count":null,"outputs":[]}]}